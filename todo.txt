;;;;;;;;;;;;;;;; Implement

; TODO: Improved Nav pessimistic description for WW

; TODO TODO: :full graph is incorrect; we either need to turn off
  duplicate plan elimination, or somehow merge ancestor sets. 

; TODO TODO TODO: <= != < or =; graph-add-and-check! is incorrect, misses
  pruning opps?   ? ? ?  Missed this because its onl a problem for
  non-simple valuations.

;; TODO: turn off caching when doing the full graph thing?  Or keep
   track of "parent" pointers on a per-plan x node, not per-ALT-node basis

; TODO: check for pruning on expansion, not storage -- otherwise, can
  end up with no pruning at all (?) (two equivalent plans, each has
  cost go up by 1 each time we refine)?  Possible, but unlikely.  

;; TODO: put back finish!  Otherwise, with multiple goal states we may
   do n times worse where n is # of goal states.

; Ideally, pruning condition should reduce to A* graph given
  consistency, flat strips hierarchy.
; Suppose we assume consistency.

; Inconsistency of, e.g., WW heuristic can be a real problem.

; Current implemementatino of :full pruning is incorrect, since we
  must merge ancestor sets when we re-generate a plan.  Might as well
  turn off duplicate plan elimination in this setting ?

; TODO: ALT should only record weak pruning for cycle graph.

; TODO: replacement policy should also be stricter-- always replace if
  you're equal.  

; Prefix check (????) 



; Add consistency enforcement to ALT, or graph search is incorrect. ?

; To ALT pruning condition, add "prune weakly if primitive prefix." ?

; Fix ALT in case of overlapping plans. (check up on this also.)

; Remove hack to ALT to show prettier graphs.


; Check on A*-graph/sloppy ALT discrepancies. (tiebreak upper-reward-bound?)

Clause-based subsumption for ALTs. (will help with WW navigation ?)s

; Think about other invalidation strategies. 

  Auto-merging above and beyond what's given.  (based on same opt-sets &
set of plans to go.  Store with each node, minimal rep. of
plan-to-go??)
 - How do we find this?  In WW and NS, "Strips-top-level" is always
 fair?  sort-of  
 - Option to turn off suffixes.
 - Try for more structure sharing
   - Merge remaining plans when we merge.  (?)  
    - Full forward-minimization is now possible.  Just merge next-maps


- When we auto-merge, how do we deal with duplicate plans?
  - Even if none, may arise when we start refining ...

  ALGs should have some mode for finding suboptimal plans.
 - Is there a simple Weighted A*/AHSS-like algorithm for ALGs, and what does it look like? Specifically, it seems like extracting optimistic state sequences may be the wrong thing to do here (instead, bias things to include more pessimistic states in the sequences?).
 TODO: a way to implement extract-a-solution (or refine potentially suboptimal things...)

 If we make things look worse in early part of the graph, we have to
touch *everything* to fix it.  Partial way around this by keeping
track of "delta"?


;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;; Minor


- Going backwards, keep track of the reward of the second-best path. 

 - After refining a node, instead of returning directly to the root, progress forward along the optimal state sequence.  If at any point the progressed valuation assigns the regressed state a reward corresponding to a plan at least as good as the second-best path, call backwards-pass starting at this node.

 - At the other end, cache the max-gap for the current state sequence going forward from the root.  If, during a backwards pass, you hit the cached state sequence and the current max-gap is > the cached one, stop going backwards and refine right away.


;;;;;;;;;;;;;;;; Think About

 Incremental expansion.

 How to use pessimistic descriptions in ALG

hierarchical preconditions -> bhaskara  (lots more spurious states).

- What's the relationship, if any, between optimal ALG search and
  algorithms like AO*?  

 - Enforce consistency, add assertions back to sbp - difficult for
   non-simple valuations.
   - Option is to keep hierarchical structure, re-progress ... ?


;;;;;;;;;;;;;;;; General TODO


;;;;;;;;;;;;;;;;; Progression/subsumption efficiency

 - Incremental progression/merging.  It should be possible to progress only "diffs" going forward, since usually only small changes will have been made to the valuations.  This will probably be very important if the valuations get very large.  Similar indexing may allow more efficiently finding the best precursor (for OR-nodes) and the best regressed state (for AND-nodes).

Incremental progression v.2. (only progress best clauses first...) -- could
allow more merging without degenerating to symbolic BFS.

Clauses record provenance.  Assume optimsitic consistency.  rewards
always go down.  Can only affect some subest of progressed results.
By decreasing reward by x for decreased by x, or by anything for
killed state.

(If doing fancy valuation tricks, much watch out for
identitydescrpition, conditional, ...)

Might as well store provenance too, for regression ...
... and implement incremental progression/merging?
 -- But problem with provenance is things may be OK even if 
    valuation is out of date, in which case chain is invalid
    ... . . . . ...?

; Smarter way to compare vectors of rewards in subsumption ...


Better to regress partial clauses ...




---------------------------------------------------------


Later

Fancier PDF display ?

Ideas on probabilistic descriptions, synthesis, starting with flat
hierarchy, learning descriptions, macros, hierarchies bottom up.
Useful HLAs are ones with high success probability, low computational
complexity.   All of these things are context-sensitive, can be
imprecise, except for solid opt/pess descriptions.  

TODO: figure out what to do with forall conditions in NCSTRIPS.

