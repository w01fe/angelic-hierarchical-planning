;;;;;;;;;;;;;;;; Implement

Bug with online, when used with hierarchy and pruning.
  - Issue is with reward-adjust-node ... make "reward-to-finish"
  action?  
  - TODO: ... but, why does it happen only with pruning ? 

TODO: enforce consistency in AHLRTA*

Figure out if was-tight? is correct condition, get rid of it?
Seems correct (implies complex condition)?

Description of ahlrta* in ICAPS paper is wrong too ?!?!?!
  - Missing "plan is primitive" step?s
  - OR, more concisely, if min f-cost plan is primitive, break;

Search through TODOs.

Add tests for decomposed, weighted, optimistic offline algs. 

Note about consistency with AHLRTA* -- have a flag on descriptions for
consistent?, raise extra errors when true ?

;;;;;;;;;;;;;;;; General TODO

 
Later


Add NCStrips tests.

Fancier PDF display ?

Ideas on probabilistic descriptions, synthesis, starting with flat
hierarchy, learning descriptions, macros, hierarchies bottom up.
Useful HLAs are ones with high success probability, low computational
complexity.   All of these things are context-sensitive, can be
imprecise, except for solid opt/pess descriptions.  

Check up on forall conditions in NCSTRIPS.

